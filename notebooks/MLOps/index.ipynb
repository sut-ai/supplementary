{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDerBS_foQl2"
   },
   "source": [
    "# MLOps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5z34ayPNA13"
   },
   "source": [
    "# Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Machine Learning Lifecycle](#mll)\n",
    "3. [MLOps Tools](#tools)\n",
    "  * [Data Management](#data)\n",
    "  * [Modeling](#model)\n",
    "  * [Operationalization](#operation)\n",
    "4. [Example](#code_example)\n",
    "5. [Conclusion](#conclusion)\n",
    "6. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OotVuBgfqME"
   },
   "source": [
    "## Introduction <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeHq0bAh4c2u"
   },
   "source": [
    "MLOps, also known as Machine Learning Operations for Production, is a set of standardized practices that can be utilized to build, deploy, and govern the lifecycle of ML models. This setup helps to ease the interaction among cross-functional teams and provides an automated platform to keep track of everything required for the complete cycle of ML models. MLOps practices also result in increased scalability, security, and reliability of the ML systems, leading to shorter development cycles and escalated profits from the ML projects.  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://ml-ops.org/img/mlops-loop-en.jpg\" \n",
    "   width=\"600\" \n",
    "     height=\"600\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYV4Z8O_fqMF"
   },
   "source": [
    "## Machine Learning Lifecycle <a name=\"mll\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-thmGRK44qD6"
   },
   "source": [
    "MLOps lifecycle has seven different stages. All the processes happen iteratively, and the success of the entire machine learning system comes with the successful execution of each of these stages.\n",
    "\n",
    "The machine learning lifecycle is the process of developing, deploying, and managing a machine learning model for a specific application. The lifecycle typically consists of:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.devopsschool.com/blog/wp-content/uploads/2022/03/1_i5TcWMCV6P1B7kmoblUFow-1536x745.png\"\n",
    "     width=\"900\" \n",
    "     height=\"500\"/>\n",
    "</p>\n",
    "\n",
    "ML Development: This is the basic step that involves creating a complete pipeline beginning from data processing to model training and evaluation codes. \n",
    "\n",
    "Model Training: Once the setup is ready, the next logical step is to train the model. Here, continuous training functionality is also needed to adapt to new data or address specific changes. \n",
    "\n",
    "Model Evaluation: Performing inference over the trained model and checking the accuracy/correctness of the output results. \n",
    "\n",
    "Model Deployment: When the proof of concept stage is accomplished, the other part is to deploy the model according to the industry requirements to face the real-life data. \n",
    "\n",
    "Prediction Serving: After deployment, the model is now ready to serve predictions over the incoming data. \n",
    "\n",
    "Model Monitoring: Over time, problems such as concept drift can make the results inaccurate hence continuous monitoring of the model is essential to ensure proper functioning. \n",
    "\n",
    "Data and Model Management: It is a part of the central system that manages the data and models. It includes maintaining storage, keeping track of different versions, ease of accessibility, security, and configuration across various cross-functional teams. \n",
    "\n",
    "\n",
    "Models are deployed across the organization and in various systems without a consistent way to monitor them. Models have been in production for a long time and never refreshed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEn8GUyrfqMO"
   },
   "source": [
    "## MLOps Tools <a name=\"tools\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjLahM_Vbqz2"
   },
   "source": [
    "One of the challenges in ML lifecycle management is manual labor. Every step and the transition between steps are manual. It means data scientists need to collect, analyze, and process data for each application manually. They need to examine their older models to develop new ones and manually fine-tune each time. A large amount of time is allocated to model monitoring to prevent performance degradation. A successful deployment of machine learning models at scale requires automation of steps of the lifecycle. Automation decreases the time allocated to resource-consuming steps such as feature engineering, model training, monitoring, and retraining. It frees up time to rapidly experiment with new models.\n",
    "\n",
    "The MLOps tools help organizations apply DevOps practices to the process of creating and using AI and machine learning models. These tools are typically used by machine learning engineers, data scientists, and DevOps engineers. MLOps tools can be divided into three major areas.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://neptune.ai/wp-content/uploads/GreenSteam-MLOPs-toolstack_1.png\"\n",
    "     width=\"900\" \n",
    "     height=\"500\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4ZBEZCDfqMO"
   },
   "source": [
    "### Data Management <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcGXgwZ_fqMP"
   },
   "source": [
    "MLOps Tools for data management consist of data labeling tools which are used to label large volumes of data such as texts, images, or audios and data versioning tools which enable managing different versions of datasets and storing them in an accessible and well-organized way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoqWqW24fqMQ"
   },
   "source": [
    "### Modeling <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L4mL1nt5d99"
   },
   "source": [
    "MLOps Tools for modeling consist of feature engineering tools that automate the process of extracting useful features from raw datasets to create better training data for machine learning models like [Feast](https://github.com/feast-dev/feast). Another tool is for experiment tracking which save all the necessary information about different experiments like [MLFlow](https://mlflow.org) and the last tool is for Hyperparameter Optimization that automate the process of searching and selecting hyperparameters that give optimal performance for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UstdBiu75eKS"
   },
   "source": [
    "### Operationalization <a name=\"operation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxixV6SG6ldE"
   },
   "source": [
    "MLOps Tools for operationalization consist of model deployment tools which facilitate integrating ML models into a production environment to make predictions like [Kubeflow](https://www.kubeflow.org). the other tool concerning operationalization is for model monitoring which detect data drifts and anomalies over time and allow setting up alerts in case of performance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29Hx95TFfqMU"
   },
   "source": [
    "## Example <a name=\"code_example\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdJiNHvH6nWn"
   },
   "source": [
    "In this section we see an example of ml lifrcycle using MLFlow. MLflow is an open source platform for managing the end-to-end machine learning lifecycle. It is designed to work with any machine learning library, determine most things about your code by convention, and require minimal changes to integrate into an existing codebase.\n",
    "First, we install and import nessecary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our metric for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we first read the wine-quality csv file from the URL and then split the data into training and test sets.\n",
    "Then, we split the target from our data set which is the quality column and at the end we register our model.\n",
    "\n",
    "The mlflow.start_run function start a new MLflow run, setting it as the active run under which metrics and parameters will be logged, mlflow.log_metric function logs a single key-value metric, mlflow.log_param function logs a single key-value param in the currently active run, mlflow.log_artifact function logs a local file or directory as an artifact and mlflow.set_tracking_uri function set tracking store URI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# !pip install mlflow\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "\n",
    "csv_url = (\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\")\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=\";\")\n",
    "except Exception as e:\n",
    "    logger.exception(\"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "alpha = float(sys.argv[1]) if len(sys.argv) > 1 else 0.5\n",
    "l1_ratio = float(sys.argv[2]) if len(sys.argv) > 2 else 0.5\n",
    "\n",
    "with mlflow.start_run():\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    if tracking_url_type_store != \"file\":\n",
    "        mlflow.sklearn.log_model(lr, \"model\", registered_model_name=\"ElasticnetWineModel\")\n",
    "    else:\n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.600000, l1_ratio=0.800000):\n",
      "  RMSE: 0.8326325509502465\n",
      "  MAE: 0.6676500690618903\n",
      "  R2: 0.0177082428508879\n"
     ]
    }
   ],
   "source": [
    "!python train.py 0.6 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we serve our model which is to host machine-learning models (on the cloud or on premises) and to make their functions available via API so that applications can incorporate AI into their systems. Model serving is crucial, as a business cannot offer AI products to a large user base without making its product accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models serve -m \"/Users/model\"  --no-conda -p 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to deploy our model using ducker. First we build the image and then deploy it to our cluster. One way to do this is by applying the respective Kubernetes manifests through the kubectl CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models build-docker \\\n",
    "  -m ./mlruns/0/d1a8010b10f84f5a9b0a51e2b420efb2/artifacts/model \\\n",
    "  -n my-docker-image \\\n",
    "  --enable-mlserver\n",
    "\n",
    "!kubectl apply -f my-config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile my-manifest.yaml\n",
    "\n",
    "apiVersion: serving.kserve.io/v1beta1\n",
    "kind: InferenceService\n",
    "metadata:\n",
    "  name: mlflow-model\n",
    "spec:\n",
    "  predictor:\n",
    "    containers:\n",
    "      - name: mlflow-model\n",
    "        image: my-docker-image\n",
    "        ports:\n",
    "          - containerPort: 8080\n",
    "            protocol: TCP\n",
    "        env:\n",
    "          - name: PROTOCOL\n",
    "            value: v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BDIzkJhfqMV"
   },
   "source": [
    "## Conclusion <a name=\"conclusion\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAfujAPs6n1B"
   },
   "source": [
    "MLOps solution provides data scientists with an easier and efficient way to maintain monitor models. By getting models into production and bridging the gap between the stakeholder teams, they can focus on data science. With the help of MLOps, deployment can be done on any platform.\n",
    "\n",
    "In this nootboke we talk about MLOps and its lifecycle and the nessecity of using it. and at the end we saw an simple example of developing and deploying a model using MLFlow which is a library used for MLOps in python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a name=\"references\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MLOps concepts for busy engineers: model serving](https://spell.ml/blog/mlops-concepts-model-serving-X385lREAACcAAGzS)\n",
    "<br>\n",
    "[MLOps Principles](https://ml-ops.org/content/mlops-principles)\n",
    "<br>\n",
    "[MLOps Python Tutorial for Beginners -Get Started with MLOps](https://www.projectpro.io/data-science-in-python-tutorial/mlops-python-tutorial-for-beginners#mcetoc_1fglt18dug)\n",
    "<br>\n",
    "[The MLOps–A Complete Guide and tutorial](https://www.devopsschool.com/blog/the-mlops-a-complete-guide-and-tutorial/)\n",
    "<br>\n",
    "[Machine Learning, Pipelines, Deployment and MLOps Tutorial](https://www.datacamp.com/tutorial/tutorial-machine-learning-pipelines-mlops-deployment#why-mlops-)\n",
    "<br>\n",
    "[Introduction to MLOps](https://www.youtube.com/watch?v=Kvxaj6pHeVA)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "index.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
